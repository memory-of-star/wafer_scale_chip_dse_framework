test_model_parameters = [{
        "attention_heads": 24,
        "hidden_size": 2304,
        "sequence_length": 2048,
        "number_of_layers": 24,
        "mini_batch_size": 512,
        "micro_batch_size": 512,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 32,
        "hidden_size": 3072,
        "sequence_length": 2048,
        "number_of_layers": 30,
        "mini_batch_size": 512,
        "micro_batch_size": 512,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 32,
        "hidden_size": 4096,
        "sequence_length": 2048,
        "number_of_layers": 36,
        "mini_batch_size": 512,
        "micro_batch_size": 512,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 48,
        "hidden_size": 6144,
        "sequence_length": 2048,
        "number_of_layers": 40,
        "mini_batch_size": 1024,
        "micro_batch_size": 1024,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 64,
        "hidden_size": 8192,
        "sequence_length": 2048,
        "number_of_layers": 48,
        "mini_batch_size": 1536,
        "micro_batch_size": 1536,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 80,
        "hidden_size": 10240,
        "sequence_length": 2048,
        "number_of_layers": 60,
        "mini_batch_size": 1792,
        "micro_batch_size": 1792,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 96,
        "hidden_size": 12288,
        "sequence_length": 2048,
        "number_of_layers": 80,
        "mini_batch_size": 2304,
        "micro_batch_size": 2304,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 128,
        "hidden_size": 16384,
        "sequence_length": 2048,
        "number_of_layers": 96,
        "mini_batch_size": 2160,
        "micro_batch_size": 2160,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 128,
        "hidden_size": 20480,
        "sequence_length": 2048,
        "number_of_layers": 105,
        "mini_batch_size": 2520,
        "micro_batch_size": 2520,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 160,
        "hidden_size": 25600,
        "sequence_length": 2048,
        "number_of_layers": 128,
        "mini_batch_size": 3072,
        "micro_batch_size": 3072,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 256,
        "hidden_size": 32000,
        "sequence_length": 2048,
        "number_of_layers": 192,
        "mini_batch_size": 3072,
        "micro_batch_size": 3072,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 432,
        "hidden_size": 43200,
        "sequence_length": 2048,
        "number_of_layers": 192,
        "mini_batch_size": 5500,
        "micro_batch_size": 5500,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 512,
        "hidden_size": 66560,
        "sequence_length": 2048,
        "number_of_layers": 195,
        "mini_batch_size": 10000,
        "micro_batch_size": 10000,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 620,
        "hidden_size": 80600,
        "sequence_length": 2048,
        "number_of_layers": 240,
        "mini_batch_size": 15000,
        "micro_batch_size": 15000,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 850,
        "hidden_size": 102000,
        "sequence_length": 2048,
        "number_of_layers": 270,
        "mini_batch_size": 20000,
        "micro_batch_size": 20000,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    {
        "attention_heads": 1024,
        "hidden_size": 158720,
        "sequence_length": 2048,
        "number_of_layers": 315,
        "mini_batch_size": 20000,
        "micro_batch_size": 20000,
        "data_parallel_size": 8,
        "model_parallel_size": 1,
        "tensor_parallel_size": 1,
    },
    ]
