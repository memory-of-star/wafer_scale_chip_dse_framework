{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(DEBUG) 2023-04-10 22:54:25,073 [logger.py:40] logger init.\n",
      "(INFO) 2023-04-10 22:54:25,074 [logger.py:42] Logfile /home/chenyiqi/wafer_scale_chip_dse_framework/log/DSE4WSE_2023-04-10-22-54-25-073455.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from utility import dse, parse_pickle\n",
    "\n",
    "x = parse_pickle.parse_pickle('v0.1')\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_curve(histories, strategy='multi_fidelity'):\n",
    "    if strategy == 'multi_fidelity':\n",
    "        _sum = [None, None]\n",
    "        for i in range(len(histories)):\n",
    "            for j in range(2):\n",
    "                tmp = np.array([k[-1] for k in histories[i][j]])\n",
    "                if not isinstance(_sum[j], np.ndarray):\n",
    "                    _sum[j] = tmp\n",
    "                else:\n",
    "                    if len(_sum[j]) > len(tmp):\n",
    "                        tmp = np.pad(tmp, (0, len(_sum[j]) - len(tmp)), mode='edge')\n",
    "                    else:\n",
    "                        _sum[j] = np.pad(_sum[j], (0, len(tmp) - len(_sum[j])), mode='edge')\n",
    "                    _sum[j] += tmp\n",
    "    elif strategy == 'random' or strategy == 'single_fidelity':\n",
    "        _sum = None\n",
    "        for i in range(len(histories)):\n",
    "            tmp = np.array([k[-1] for k in histories[i]])\n",
    "            if not isinstance(_sum, np.ndarray):\n",
    "                _sum = tmp\n",
    "            else:\n",
    "                if len(_sum) > len(tmp):\n",
    "                    tmp = np.pad(tmp, (0, len(_sum) - len(tmp)), mode='edge')\n",
    "                else:\n",
    "                    _sum = np.pad(_sum, (0, len(tmp) - len(_sum)), mode='edge')\n",
    "                _sum += tmp\n",
    "    return _sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sum = [None, None]\n",
    "\n",
    "for i in range(len(x)):\n",
    "    for j in range(2):\n",
    "        tmp = np.array([k[-1] for k in x[i][j]])\n",
    "        if not isinstance(sum[j], np.ndarray):\n",
    "            sum[j] = tmp\n",
    "        else:\n",
    "            if len(sum[j]) > len(tmp):\n",
    "                tmp = np.pad(tmp, (0, len(sum[j]) - len(tmp)), mode='edge')\n",
    "            else:\n",
    "                sum[j] = np.pad(sum[j], (0, len(tmp) - len(sum[j])), mode='edge')\n",
    "            sum[j] += tmp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "curve1 = -sum[0] / len(x)\n",
    "curve2 = -sum[1] / len(x)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(len(curve1)), curve1)\n",
    "plt.plot(np.arange(len(curve2)), curve2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "x_ = parse_pickle.parse_pickle('random_v0.1', strategy='random')\n",
    "print(len(x_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(x_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sum = get_curve(x_, strategy='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "curve1 = -sum[0] / len(x)\n",
    "curve2 = -sum[1] / len(x)\n",
    "random_curve = -random_sum / len(x_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(len(curve1)), curve1)\n",
    "# plt.plot(np.arange(len(curve2)), curve2)\n",
    "plt.plot(np.arange(len(random_curve)), random_curve)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(DEBUG) 2023-04-14 12:49:01,833 [logger.py:40] logger init.\n",
      "(INFO) 2023-04-14 12:49:01,834 [logger.py:42] Logfile /home/chenyiqi/wafer_scale_chip_dse_framework/log/DSE4WSE_2023-04-14-12-49-01-833000.log\n",
      "100%|██████████| 100/100 [00:00<00:00, 400.18it/s]\n",
      "(INFO) 2023-04-14 12:49:05,935 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 32, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 18, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:05,936 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 292, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 20}\n",
      "(INFO) 2023-04-14 12:49:05,941 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,045 [api1.py:131] throughput: 1.0449500203804825\n",
      "(INFO) 2023-04-14 12:49:06,046 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 32, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 18, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:06,046 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 292, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 20}\n",
      "(INFO) 2023-04-14 12:49:06,049 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,050 [api2.py:131] throughput: 0.5517771530249164\n",
      "(INFO) 2023-04-14 12:49:06,051 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 2048, 'core_mac_num': 32, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 13, 'reticle_array_w': 17}\n",
      "(INFO) 2023-04-14 12:49:06,052 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 10, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 33}\n",
      "(INFO) 2023-04-14 12:49:06,057 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,174 [api1.py:131] throughput: 0.8923690799716449\n",
      "(INFO) 2023-04-14 12:49:06,175 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 2048, 'core_mac_num': 32, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 13, 'reticle_array_w': 17}\n",
      "(INFO) 2023-04-14 12:49:06,176 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 10, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 33}\n",
      "(INFO) 2023-04-14 12:49:06,179 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,181 [api2.py:131] throughput: 1.0615246583561182\n",
      "(INFO) 2023-04-14 12:49:06,182 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 8, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:06,183 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 27, 'data_parallel_size': 7, 'model_parallel_size': 12, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:06,187 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,250 [api1.py:131] throughput: 0.2605792681299798\n",
      "(INFO) 2023-04-14 12:49:06,251 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 8, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:06,252 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 27, 'data_parallel_size': 7, 'model_parallel_size': 12, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:06,254 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,256 [api2.py:131] throughput: 12.861352561569866\n",
      "(INFO) 2023-04-14 12:49:06,257 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 2048, 'core_mac_num': 128, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 14, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:06,258 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 231, 'data_parallel_size': 1, 'model_parallel_size': 8, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:06,262 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,355 [api1.py:131] throughput: 0.0735050955378741\n",
      "(INFO) 2023-04-14 12:49:06,356 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 2048, 'core_mac_num': 128, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 14, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:06,357 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 231, 'data_parallel_size': 1, 'model_parallel_size': 8, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:06,360 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,361 [api2.py:131] throughput: 0.7283355265805093\n",
      "(INFO) 2023-04-14 12:49:06,362 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 1024, 'core_mac_num': 16, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 15}\n",
      "(INFO) 2023-04-14 12:49:06,362 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 67, 'data_parallel_size': 3, 'model_parallel_size': 24, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:06,364 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,437 [api1.py:131] throughput: 0.20088696047920807\n",
      "(INFO) 2023-04-14 12:49:06,438 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 1024, 'core_mac_num': 16, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 15}\n",
      "(INFO) 2023-04-14 12:49:06,439 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 67, 'data_parallel_size': 3, 'model_parallel_size': 24, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:06,441 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,443 [api2.py:131] throughput: 19.78286830193228\n",
      "(INFO) 2023-04-14 12:49:06,444 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 16, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 13}\n",
      "(INFO) 2023-04-14 12:49:06,445 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 498, 'data_parallel_size': 1, 'model_parallel_size': 8, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:06,450 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,549 [api1.py:131] throughput: 0.07213054879564919\n",
      "(INFO) 2023-04-14 12:49:06,550 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 16, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 13}\n",
      "(INFO) 2023-04-14 12:49:06,550 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 498, 'data_parallel_size': 1, 'model_parallel_size': 8, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:06,554 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,555 [api2.py:131] throughput: 0.6311230776458668\n",
      "(INFO) 2023-04-14 12:49:06,556 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 8, 'core_noc_bw': 4096, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 14}\n",
      "(INFO) 2023-04-14 12:49:06,557 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 24, 'data_parallel_size': 11, 'model_parallel_size': 6, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:06,559 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,631 [api1.py:131] throughput: 0.814648153630032\n",
      "(INFO) 2023-04-14 12:49:06,632 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 8, 'core_noc_bw': 4096, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 14}\n",
      "(INFO) 2023-04-14 12:49:06,633 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 24, 'data_parallel_size': 11, 'model_parallel_size': 6, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:06,635 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,637 [api2.py:131] throughput: 1.7535382755040057\n",
      "(INFO) 2023-04-14 12:49:06,638 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 32, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 25, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:06,639 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 106, 'data_parallel_size': 2, 'model_parallel_size': 12, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:06,644 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,880 [api1.py:131] throughput: 0.07735889707503704\n",
      "(INFO) 2023-04-14 12:49:06,881 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 32, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 25, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:06,882 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 106, 'data_parallel_size': 2, 'model_parallel_size': 12, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:06,886 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,889 [api2.py:131] throughput: 1.603249810938626\n",
      "(INFO) 2023-04-14 12:49:06,890 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 8, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 56, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:06,891 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 62, 'data_parallel_size': 3, 'model_parallel_size': 6, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:06,894 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,953 [api1.py:131] throughput: 0.5839413548725036\n",
      "(INFO) 2023-04-14 12:49:06,953 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 8, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 56, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:06,954 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 62, 'data_parallel_size': 3, 'model_parallel_size': 6, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:06,956 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:06,957 [api2.py:131] throughput: 1.8649928957198625\n",
      "(INFO) 2023-04-14 12:49:06,958 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 2048, 'core_mac_num': 64, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:06,960 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 423, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:06,964 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,139 [api1.py:131] throughput: 0.14982694474369962\n",
      "(INFO) 2023-04-14 12:49:07,141 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 2048, 'core_mac_num': 64, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:07,142 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 423, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:07,146 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,147 [api2.py:131] throughput: 0.37933713747321895\n",
      "(INFO) 2023-04-14 12:49:07,148 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 18, 'reticle_array_w': 36}\n",
      "(INFO) 2023-04-14 12:49:07,149 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 95, 'data_parallel_size': 5, 'model_parallel_size': 3, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 19}\n",
      "(INFO) 2023-04-14 12:49:07,160 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,584 [api1.py:131] throughput: 0.9019077846125304\n",
      "(INFO) 2023-04-14 12:49:07,585 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 18, 'reticle_array_w': 36}\n",
      "(INFO) 2023-04-14 12:49:07,586 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 95, 'data_parallel_size': 5, 'model_parallel_size': 3, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 19}\n",
      "(INFO) 2023-04-14 12:49:07,592 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,593 [api2.py:131] throughput: 0.7980184604354904\n",
      "(INFO) 2023-04-14 12:49:07,594 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 1024, 'core_mac_num': 4, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 56, 'wafer_mem_bw': 900, 'reticle_array_h': 31, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:07,594 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 9, 'data_parallel_size': 5, 'model_parallel_size': 1, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 127}\n",
      "(INFO) 2023-04-14 12:49:07,598 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,698 [api1.py:131] throughput: 1.4484684520326576\n",
      "(INFO) 2023-04-14 12:49:07,699 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 1024, 'core_mac_num': 4, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 56, 'wafer_mem_bw': 900, 'reticle_array_h': 31, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:07,699 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 9, 'data_parallel_size': 5, 'model_parallel_size': 1, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 127}\n",
      "(INFO) 2023-04-14 12:49:07,702 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,704 [api2.py:131] throughput: 15.765085750081468\n",
      "(INFO) 2023-04-14 12:49:07,705 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 64, 'core_array_w': 72, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:07,705 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 418, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:07,709 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,741 [api1.py:131] throughput: 0.11554163938774775\n",
      "(INFO) 2023-04-14 12:49:07,741 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 64, 'core_array_w': 72, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:07,742 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 418, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:07,743 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,744 [api2.py:131] throughput: 0.42807662483001135\n",
      "(INFO) 2023-04-14 12:49:07,744 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 2048, 'core_mac_num': 32, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:07,745 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 87, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 73}\n",
      "(INFO) 2023-04-14 12:49:07,747 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,793 [api1.py:131] throughput: 1.053896267598499\n",
      "(INFO) 2023-04-14 12:49:07,794 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 2048, 'core_mac_num': 32, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:07,794 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 87, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 73}\n",
      "(INFO) 2023-04-14 12:49:07,796 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,797 [api2.py:131] throughput: 260.53325232295737\n",
      "(INFO) 2023-04-14 12:49:07,798 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 40}\n",
      "(INFO) 2023-04-14 12:49:07,798 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 55, 'data_parallel_size': 4, 'model_parallel_size': 6, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 32}\n",
      "(INFO) 2023-04-14 12:49:07,802 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,935 [api1.py:131] throughput: 4.25153964236239\n",
      "(INFO) 2023-04-14 12:49:07,936 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 40}\n",
      "(INFO) 2023-04-14 12:49:07,937 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 55, 'data_parallel_size': 4, 'model_parallel_size': 6, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 32}\n",
      "(INFO) 2023-04-14 12:49:07,939 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:07,941 [api2.py:131] throughput: 1.949557504722109\n",
      "(INFO) 2023-04-14 12:49:07,942 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 32, 'core_noc_bw': 2048, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:07,943 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 160, 'data_parallel_size': 3, 'model_parallel_size': 6, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:07,945 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,019 [api1.py:131] throughput: 0.14288020747833818\n",
      "(INFO) 2023-04-14 12:49:08,020 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 32, 'core_noc_bw': 2048, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:08,021 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 160, 'data_parallel_size': 3, 'model_parallel_size': 6, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:08,022 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,023 [api2.py:131] throughput: 0.9025247820308792\n",
      "(INFO) 2023-04-14 12:49:08,024 [api1.py:116] Design point: {'core_buffer_size': 512, 'core_buffer_bw': 2048, 'core_mac_num': 128, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 14}\n",
      "(INFO) 2023-04-14 12:49:08,025 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 127, 'data_parallel_size': 1, 'model_parallel_size': 24, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:08,027 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,092 [api1.py:131] throughput: 0.9450054601659483\n",
      "(INFO) 2023-04-14 12:49:08,093 [api2.py:116] Design point: {'core_buffer_size': 512, 'core_buffer_bw': 2048, 'core_mac_num': 128, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 14}\n",
      "(INFO) 2023-04-14 12:49:08,094 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 127, 'data_parallel_size': 1, 'model_parallel_size': 24, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:08,097 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,098 [api2.py:131] throughput: 44.52328033282042\n",
      "(INFO) 2023-04-14 12:49:08,099 [api1.py:116] Design point: {'core_buffer_size': 512, 'core_buffer_bw': 2048, 'core_mac_num': 8, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 21, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:08,100 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 26, 'data_parallel_size': 6, 'model_parallel_size': 8, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 17}\n",
      "(INFO) 2023-04-14 12:49:08,104 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,192 [api1.py:131] throughput: 5.128338832319191\n",
      "(INFO) 2023-04-14 12:49:08,194 [api2.py:116] Design point: {'core_buffer_size': 512, 'core_buffer_bw': 2048, 'core_mac_num': 8, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 21, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:08,195 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 26, 'data_parallel_size': 6, 'model_parallel_size': 8, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 17}\n",
      "(INFO) 2023-04-14 12:49:08,198 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,199 [api2.py:131] throughput: 2.49924830675734\n",
      "(INFO) 2023-04-14 12:49:08,200 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 2048, 'core_mac_num': 8, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 24}\n",
      "(INFO) 2023-04-14 12:49:08,201 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 163, 'data_parallel_size': 3, 'model_parallel_size': 3, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 111}\n",
      "(INFO) 2023-04-14 12:49:08,206 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,527 [api1.py:131] throughput: 8.177132389055553\n",
      "(INFO) 2023-04-14 12:49:08,528 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 2048, 'core_mac_num': 8, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 24}\n",
      "(INFO) 2023-04-14 12:49:08,529 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 163, 'data_parallel_size': 3, 'model_parallel_size': 3, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 111}\n",
      "(INFO) 2023-04-14 12:49:08,532 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,533 [api2.py:131] throughput: 1.1421947074930958\n",
      "(INFO) 2023-04-14 12:49:08,534 [api1.py:116] Design point: {'core_buffer_size': 256, 'core_buffer_bw': 2048, 'core_mac_num': 128, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 11, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:08,535 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 8, 'data_parallel_size': 1, 'model_parallel_size': 4, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:08,537 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,597 [api1.py:131] throughput: 0.3961073679581325\n",
      "(INFO) 2023-04-14 12:49:08,598 [api2.py:116] Design point: {'core_buffer_size': 256, 'core_buffer_bw': 2048, 'core_mac_num': 128, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 11, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:08,599 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 8, 'data_parallel_size': 1, 'model_parallel_size': 4, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:08,600 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,602 [api2.py:131] throughput: 1.856583678289011\n",
      "(INFO) 2023-04-14 12:49:08,602 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 2048, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 13, 'reticle_array_w': 17}\n",
      "(INFO) 2023-04-14 12:49:08,604 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 54, 'data_parallel_size': 9, 'model_parallel_size': 6, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 16}\n",
      "(INFO) 2023-04-14 12:49:08,608 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,693 [api1.py:131] throughput: 3.771319162790725\n",
      "(INFO) 2023-04-14 12:49:08,694 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 2048, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 13, 'reticle_array_w': 17}\n",
      "(INFO) 2023-04-14 12:49:08,695 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 54, 'data_parallel_size': 9, 'model_parallel_size': 6, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 16}\n",
      "(INFO) 2023-04-14 12:49:08,698 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,700 [api2.py:131] throughput: 1.6273613142859196\n",
      "(INFO) 2023-04-14 12:49:08,701 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 32, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 56, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:08,702 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 24, 'data_parallel_size': 2, 'model_parallel_size': 8, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:08,704 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,740 [api1.py:131] throughput: 0.20099900594850473\n",
      "(INFO) 2023-04-14 12:49:08,741 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 32, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 56, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:08,742 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 24, 'data_parallel_size': 2, 'model_parallel_size': 8, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:08,743 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,744 [api2.py:131] throughput: 2.822409916674976\n",
      "(INFO) 2023-04-14 12:49:08,745 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 16, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 80, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:08,746 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 247, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:08,748 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,783 [api1.py:131] throughput: 0.17210616382024796\n",
      "(INFO) 2023-04-14 12:49:08,784 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 16, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 80, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:08,785 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 247, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:08,786 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,787 [api2.py:131] throughput: 0.5655555127429195\n",
      "(INFO) 2023-04-14 12:49:08,787 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 16, 'core_noc_bw': 2048, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 28}\n",
      "(INFO) 2023-04-14 12:49:08,788 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 20, 'data_parallel_size': 5, 'model_parallel_size': 12, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 21}\n",
      "(INFO) 2023-04-14 12:49:08,792 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,903 [api1.py:131] throughput: 6.2299190130464055\n",
      "(INFO) 2023-04-14 12:49:08,904 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 16, 'core_noc_bw': 2048, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 28}\n",
      "(INFO) 2023-04-14 12:49:08,905 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 20, 'data_parallel_size': 5, 'model_parallel_size': 12, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 21}\n",
      "(INFO) 2023-04-14 12:49:08,908 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:08,909 [api2.py:131] throughput: 3.576636387585149\n",
      "(INFO) 2023-04-14 12:49:08,910 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 20}\n",
      "(INFO) 2023-04-14 12:49:08,911 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 15, 'data_parallel_size': 6, 'model_parallel_size': 1, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 40}\n",
      "(INFO) 2023-04-14 12:49:08,914 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,049 [api1.py:131] throughput: 0.6615085174862968\n",
      "(INFO) 2023-04-14 12:49:09,050 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 20}\n",
      "(INFO) 2023-04-14 12:49:09,050 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 15, 'data_parallel_size': 6, 'model_parallel_size': 1, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 40}\n",
      "(INFO) 2023-04-14 12:49:09,053 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,054 [api2.py:131] throughput: 0.5296262734656132\n",
      "(INFO) 2023-04-14 12:49:09,055 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 2048, 'core_mac_num': 32, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 17, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:09,055 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 3, 'data_parallel_size': 2, 'model_parallel_size': 6, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 3}\n",
      "(INFO) 2023-04-14 12:49:09,057 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,159 [api1.py:131] throughput: 0.6759154176518224\n",
      "(INFO) 2023-04-14 12:49:09,160 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 2048, 'core_mac_num': 32, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 17, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:09,161 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 3, 'data_parallel_size': 2, 'model_parallel_size': 6, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 3}\n",
      "(INFO) 2023-04-14 12:49:09,163 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,164 [api2.py:131] throughput: 2.408304948473217\n",
      "(INFO) 2023-04-14 12:49:09,166 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 16, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 64, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:09,167 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 76, 'data_parallel_size': 2, 'model_parallel_size': 4, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 11}\n",
      "(INFO) 2023-04-14 12:49:09,169 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,213 [api1.py:131] throughput: 0.33854466026321345\n",
      "(INFO) 2023-04-14 12:49:09,214 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 16, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 64, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:09,215 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 76, 'data_parallel_size': 2, 'model_parallel_size': 4, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 11}\n",
      "(INFO) 2023-04-14 12:49:09,216 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,217 [api2.py:131] throughput: 95.4109273003984\n",
      "(INFO) 2023-04-14 12:49:09,218 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 128, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 13, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:09,219 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 373, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:09,221 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,289 [api1.py:131] throughput: 0.05227862870310124\n",
      "(INFO) 2023-04-14 12:49:09,290 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 128, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 13, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:09,290 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 373, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:09,292 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,293 [api2.py:131] throughput: 0.5262590169066128\n",
      "(INFO) 2023-04-14 12:49:09,294 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 4, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 11, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:09,295 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 48, 'data_parallel_size': 6, 'model_parallel_size': 6, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 9}\n",
      "(INFO) 2023-04-14 12:49:09,297 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,366 [api1.py:131] throughput: 0.6129855767211605\n",
      "(INFO) 2023-04-14 12:49:09,367 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 4, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 11, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:09,368 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 48, 'data_parallel_size': 6, 'model_parallel_size': 6, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 9}\n",
      "(INFO) 2023-04-14 12:49:09,370 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,372 [api2.py:131] throughput: 2.0864225280034328\n",
      "(INFO) 2023-04-14 12:49:09,373 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 16, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:09,374 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 148, 'data_parallel_size': 3, 'model_parallel_size': 3, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 12}\n",
      "(INFO) 2023-04-14 12:49:09,376 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,405 [api1.py:131] throughput: 1.4285186631734927\n",
      "(INFO) 2023-04-14 12:49:09,405 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 16, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:09,406 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 148, 'data_parallel_size': 3, 'model_parallel_size': 3, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 12}\n",
      "(INFO) 2023-04-14 12:49:09,407 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,408 [api2.py:131] throughput: 0.844643538263406\n",
      "(INFO) 2023-04-14 12:49:09,409 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 2048, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:09,410 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 39, 'data_parallel_size': 3, 'model_parallel_size': 8, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 13}\n",
      "(INFO) 2023-04-14 12:49:09,412 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,489 [api1.py:131] throughput: 2.1147060979434964\n",
      "(INFO) 2023-04-14 12:49:09,491 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 2048, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:09,491 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 39, 'data_parallel_size': 3, 'model_parallel_size': 8, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 13}\n",
      "(INFO) 2023-04-14 12:49:09,494 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,496 [api2.py:131] throughput: 2.1315723503539354\n",
      "(INFO) 2023-04-14 12:49:09,497 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 36}\n",
      "(INFO) 2023-04-14 12:49:09,498 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 14, 'data_parallel_size': 21, 'model_parallel_size': 24, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:09,503 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,878 [api1.py:131] throughput: 0.7229224035218221\n",
      "(INFO) 2023-04-14 12:49:09,879 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 36}\n",
      "(INFO) 2023-04-14 12:49:09,880 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 14, 'data_parallel_size': 21, 'model_parallel_size': 24, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:09,884 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:09,885 [api2.py:131] throughput: 3.608693938410392\n",
      "(INFO) 2023-04-14 12:49:09,886 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 64, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 28, 'reticle_array_w': 28}\n",
      "(INFO) 2023-04-14 12:49:09,887 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 303, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:09,899 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:10,494 [api1.py:131] throughput: 0.06409123030357211\n",
      "(INFO) 2023-04-14 12:49:10,496 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 64, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 28, 'reticle_array_w': 28}\n",
      "(INFO) 2023-04-14 12:49:10,497 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 303, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:10,503 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:10,504 [api2.py:131] throughput: 0.7044058961667865\n",
      "(INFO) 2023-04-14 12:49:10,506 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 1024, 'core_mac_num': 32, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 37, 'reticle_array_w': 51}\n",
      "(INFO) 2023-04-14 12:49:10,507 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 188, 'data_parallel_size': 1, 'model_parallel_size': 2, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 397}\n",
      "(INFO) 2023-04-14 12:49:10,529 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:12,193 [api1.py:131] throughput: 2.5271773347169746\n",
      "(INFO) 2023-04-14 12:49:12,195 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 1024, 'core_mac_num': 32, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 37, 'reticle_array_w': 51}\n",
      "(INFO) 2023-04-14 12:49:12,197 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 188, 'data_parallel_size': 1, 'model_parallel_size': 2, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 397}\n",
      "(INFO) 2023-04-14 12:49:12,219 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:12,220 [api2.py:131] throughput: 0.7490692042273289\n",
      "(INFO) 2023-04-14 12:49:12,221 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 1024, 'core_mac_num': 8, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 31, 'reticle_array_w': 14}\n",
      "(INFO) 2023-04-14 12:49:12,222 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 82, 'data_parallel_size': 6, 'model_parallel_size': 24, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:12,228 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:12,635 [api1.py:131] throughput: 0.34389765927140054\n",
      "(INFO) 2023-04-14 12:49:12,636 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 1024, 'core_mac_num': 8, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 31, 'reticle_array_w': 14}\n",
      "(INFO) 2023-04-14 12:49:12,637 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 82, 'data_parallel_size': 6, 'model_parallel_size': 24, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:12,642 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:12,643 [api2.py:131] throughput: 1.9030953250714302\n",
      "(INFO) 2023-04-14 12:49:12,644 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 64, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 35, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:12,645 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 334, 'data_parallel_size': 1, 'model_parallel_size': 1, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 60}\n",
      "(INFO) 2023-04-14 12:49:12,651 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:12,835 [api1.py:131] throughput: 0.39576036478314314\n",
      "(INFO) 2023-04-14 12:49:12,836 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 64, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 35, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:12,836 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 334, 'data_parallel_size': 1, 'model_parallel_size': 1, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 60}\n",
      "(INFO) 2023-04-14 12:49:12,840 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:12,841 [api2.py:131] throughput: 51.745162434061406\n",
      "(INFO) 2023-04-14 12:49:12,842 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 64, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 20}\n",
      "(INFO) 2023-04-14 12:49:12,843 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 407, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 3}\n",
      "(INFO) 2023-04-14 12:49:12,849 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:13,098 [api1.py:131] throughput: 0.04093280234588745\n",
      "(INFO) 2023-04-14 12:49:13,100 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 64, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 20}\n",
      "(INFO) 2023-04-14 12:49:13,101 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 407, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 3}\n",
      "(INFO) 2023-04-14 12:49:13,106 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:13,107 [api2.py:131] throughput: 0.5313526138771368\n",
      "(INFO) 2023-04-14 12:49:13,108 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 16, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:13,109 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 405, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:13,111 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:13,164 [api1.py:131] throughput: 0.06973053277333496\n",
      "(INFO) 2023-04-14 12:49:13,165 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 16, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:13,166 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 405, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:13,168 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:13,169 [api2.py:131] throughput: 0.4592025042762663\n",
      "(INFO) 2023-04-14 12:49:13,170 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 32, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 36}\n",
      "(INFO) 2023-04-14 12:49:13,171 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 168, 'data_parallel_size': 2, 'model_parallel_size': 8, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 9}\n",
      "(INFO) 2023-04-14 12:49:13,177 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:13,364 [api1.py:131] throughput: 0.5252116022923629\n",
      "(INFO) 2023-04-14 12:49:13,365 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 32, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 36}\n",
      "(INFO) 2023-04-14 12:49:13,366 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 168, 'data_parallel_size': 2, 'model_parallel_size': 8, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 9}\n",
      "(INFO) 2023-04-14 12:49:13,369 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:13,370 [api2.py:131] throughput: 1.1942597874653242\n",
      "(INFO) 2023-04-14 12:49:13,371 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 16, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 35}\n",
      "(INFO) 2023-04-14 12:49:13,371 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 162, 'data_parallel_size': 3, 'model_parallel_size': 1, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 14}\n",
      "(INFO) 2023-04-14 12:49:13,379 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:13,702 [api1.py:131] throughput: 0.6201420641976934\n",
      "(INFO) 2023-04-14 12:49:13,703 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 16, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 35}\n",
      "(INFO) 2023-04-14 12:49:13,703 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 162, 'data_parallel_size': 3, 'model_parallel_size': 1, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 14}\n",
      "(INFO) 2023-04-14 12:49:13,707 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:13,708 [api2.py:131] throughput: 0.30172645732103975\n",
      "(INFO) 2023-04-14 12:49:13,710 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 64, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 33}\n",
      "(INFO) 2023-04-14 12:49:13,711 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 215, 'data_parallel_size': 2, 'model_parallel_size': 1, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 8}\n",
      "(INFO) 2023-04-14 12:49:13,716 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:13,922 [api1.py:131] throughput: 0.41535658467312997\n",
      "(INFO) 2023-04-14 12:49:13,924 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 64, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 33}\n",
      "(INFO) 2023-04-14 12:49:13,925 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 215, 'data_parallel_size': 2, 'model_parallel_size': 1, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 8}\n",
      "(INFO) 2023-04-14 12:49:13,934 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:13,936 [api2.py:131] throughput: 0.3042155014149941\n",
      "(INFO) 2023-04-14 12:49:13,937 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 32, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 16}\n",
      "(INFO) 2023-04-14 12:49:13,938 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 332, 'data_parallel_size': 1, 'model_parallel_size': 8, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:13,943 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:14,053 [api1.py:131] throughput: 0.04815976854806679\n",
      "(INFO) 2023-04-14 12:49:14,054 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 32, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 16}\n",
      "(INFO) 2023-04-14 12:49:14,055 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 332, 'data_parallel_size': 1, 'model_parallel_size': 8, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:14,058 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:14,059 [api2.py:131] throughput: 0.584737571723817\n",
      "(INFO) 2023-04-14 12:49:14,060 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 13, 'reticle_array_w': 13}\n",
      "(INFO) 2023-04-14 12:49:14,061 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 227, 'data_parallel_size': 1, 'model_parallel_size': 4, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 19}\n",
      "(INFO) 2023-04-14 12:49:14,067 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:14,182 [api1.py:131] throughput: 0.4040189352851719\n",
      "(INFO) 2023-04-14 12:49:14,183 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 13, 'reticle_array_w': 13}\n",
      "(INFO) 2023-04-14 12:49:14,184 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 227, 'data_parallel_size': 1, 'model_parallel_size': 4, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 19}\n",
      "(INFO) 2023-04-14 12:49:14,188 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:14,190 [api2.py:131] throughput: 1.059942971257746\n",
      "(INFO) 2023-04-14 12:49:14,191 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 47}\n",
      "(INFO) 2023-04-14 12:49:14,193 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 111, 'data_parallel_size': 3, 'model_parallel_size': 4, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 134}\n",
      "(INFO) 2023-04-14 12:49:14,199 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:14,451 [api1.py:131] throughput: 6.228672408992633\n",
      "(INFO) 2023-04-14 12:49:14,452 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 47}\n",
      "(INFO) 2023-04-14 12:49:14,453 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 111, 'data_parallel_size': 3, 'model_parallel_size': 4, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 134}\n",
      "(INFO) 2023-04-14 12:49:14,458 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:14,459 [api2.py:131] throughput: 1.654290086440702\n",
      "(INFO) 2023-04-14 12:49:14,461 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 32, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:14,462 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 121, 'data_parallel_size': 1, 'model_parallel_size': 24, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:14,464 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:14,532 [api1.py:131] throughput: 0.09645235104472988\n",
      "(INFO) 2023-04-14 12:49:14,532 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 32, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:14,533 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 121, 'data_parallel_size': 1, 'model_parallel_size': 24, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:14,535 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:14,536 [api2.py:131] throughput: 1.655989201572623\n",
      "(INFO) 2023-04-14 12:49:14,536 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 16, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 56, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:14,537 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 265, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 34}\n",
      "(INFO) 2023-04-14 12:49:14,539 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:14,582 [api1.py:131] throughput: 4.11327688027586\n",
      "(INFO) 2023-04-14 12:49:14,583 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 16, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 56, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:14,584 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 265, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 34}\n",
      "(INFO) 2023-04-14 12:49:14,585 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:14,586 [api2.py:131] throughput: 1.0598553607239556\n",
      "(INFO) 2023-04-14 12:49:14,587 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 64, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 17, 'reticle_array_w': 32}\n",
      "(INFO) 2023-04-14 12:49:14,587 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 184, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:14,595 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,088 [api1.py:131] throughput: 0.053113254237523694\n",
      "(INFO) 2023-04-14 12:49:15,089 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 64, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 17, 'reticle_array_w': 32}\n",
      "(INFO) 2023-04-14 12:49:15,090 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 184, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:15,095 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,097 [api2.py:131] throughput: 0.6233968755285232\n",
      "(INFO) 2023-04-14 12:49:15,099 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 33, 'reticle_array_w': 16}\n",
      "(INFO) 2023-04-14 12:49:15,099 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 6, 'data_parallel_size': 7, 'model_parallel_size': 6, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 3}\n",
      "(INFO) 2023-04-14 12:49:15,235 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,578 [api1.py:131] throughput: 0.3281632034474925\n",
      "(INFO) 2023-04-14 12:49:15,579 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 33, 'reticle_array_w': 16}\n",
      "(INFO) 2023-04-14 12:49:15,580 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 6, 'data_parallel_size': 7, 'model_parallel_size': 6, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 3}\n",
      "(INFO) 2023-04-14 12:49:15,584 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,585 [api2.py:131] throughput: 1.8471992085830151\n",
      "(INFO) 2023-04-14 12:49:15,585 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 32, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:15,586 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 435, 'data_parallel_size': 1, 'model_parallel_size': 4, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 11}\n",
      "(INFO) 2023-04-14 12:49:15,588 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,652 [api1.py:131] throughput: 0.2901205570380864\n",
      "(INFO) 2023-04-14 12:49:15,653 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 32, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:15,654 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 435, 'data_parallel_size': 1, 'model_parallel_size': 4, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 11}\n",
      "(INFO) 2023-04-14 12:49:15,656 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,657 [api2.py:131] throughput: 0.6791493587798734\n",
      "(INFO) 2023-04-14 12:49:15,658 [api1.py:116] Design point: {'core_buffer_size': 256, 'core_buffer_bw': 2048, 'core_mac_num': 8, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 14, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:15,659 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 70, 'data_parallel_size': 7, 'model_parallel_size': 8, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:15,662 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,760 [api1.py:131] throughput: 0.19719708436425715\n",
      "(INFO) 2023-04-14 12:49:15,761 [api2.py:116] Design point: {'core_buffer_size': 256, 'core_buffer_bw': 2048, 'core_mac_num': 8, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 14, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:15,762 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 70, 'data_parallel_size': 7, 'model_parallel_size': 8, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:15,764 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,765 [api2.py:131] throughput: 1.3530186882961626\n",
      "(INFO) 2023-04-14 12:49:15,766 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 16, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 64, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:15,766 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 121, 'data_parallel_size': 2, 'model_parallel_size': 12, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:15,769 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,841 [api1.py:131] throughput: 0.27267630228805867\n",
      "(INFO) 2023-04-14 12:49:15,842 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 16, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 64, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:15,843 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 121, 'data_parallel_size': 2, 'model_parallel_size': 12, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:15,845 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,847 [api2.py:131] throughput: 1.2104570599092657\n",
      "(INFO) 2023-04-14 12:49:15,848 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 1024, 'core_mac_num': 8, 'core_noc_bw': 4096, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 20, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:15,849 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 9, 'data_parallel_size': 15, 'model_parallel_size': 1, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 39}\n",
      "(INFO) 2023-04-14 12:49:15,855 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,958 [api1.py:131] throughput: 1.0877519872732124\n",
      "(INFO) 2023-04-14 12:49:15,959 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 1024, 'core_mac_num': 8, 'core_noc_bw': 4096, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 20, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:15,959 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 9, 'data_parallel_size': 15, 'model_parallel_size': 1, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 39}\n",
      "(INFO) 2023-04-14 12:49:15,963 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:15,964 [api2.py:131] throughput: 0.5274701691203175\n",
      "(INFO) 2023-04-14 12:49:15,965 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 256, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 15}\n",
      "(INFO) 2023-04-14 12:49:15,966 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 209, 'data_parallel_size': 1, 'model_parallel_size': 6, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 10}\n",
      "(INFO) 2023-04-14 12:49:15,974 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,068 [api1.py:131] throughput: 0.3034060893821562\n",
      "(INFO) 2023-04-14 12:49:16,069 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 256, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 15}\n",
      "(INFO) 2023-04-14 12:49:16,070 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 209, 'data_parallel_size': 1, 'model_parallel_size': 6, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 10}\n",
      "(INFO) 2023-04-14 12:49:16,072 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,073 [api2.py:131] throughput: 1.0081640056556809\n",
      "(INFO) 2023-04-14 12:49:16,075 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 16, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:16,075 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 33, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:16,079 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,134 [api1.py:131] throughput: 0.3067799990558127\n",
      "(INFO) 2023-04-14 12:49:16,135 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 16, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:16,135 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 33, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:16,137 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,139 [api2.py:131] throughput: 0.8010563949279944\n",
      "(INFO) 2023-04-14 12:49:16,140 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 56, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:16,141 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 173, 'data_parallel_size': 2, 'model_parallel_size': 24, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:16,144 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,184 [api1.py:131] throughput: 0.17041390390736783\n",
      "(INFO) 2023-04-14 12:49:16,185 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 56, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:16,186 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 173, 'data_parallel_size': 2, 'model_parallel_size': 24, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:16,187 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,188 [api2.py:131] throughput: 1.0952321557717628\n",
      "(INFO) 2023-04-14 12:49:16,189 [api1.py:116] Design point: {'core_buffer_size': 512, 'core_buffer_bw': 2048, 'core_mac_num': 32, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 28}\n",
      "(INFO) 2023-04-14 12:49:16,190 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 64, 'data_parallel_size': 5, 'model_parallel_size': 4, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 17}\n",
      "(INFO) 2023-04-14 12:49:16,193 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,317 [api1.py:131] throughput: 2.7229300764062634\n",
      "(INFO) 2023-04-14 12:49:16,318 [api2.py:116] Design point: {'core_buffer_size': 512, 'core_buffer_bw': 2048, 'core_mac_num': 32, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 28}\n",
      "(INFO) 2023-04-14 12:49:16,319 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 64, 'data_parallel_size': 5, 'model_parallel_size': 4, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 17}\n",
      "(INFO) 2023-04-14 12:49:16,324 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,325 [api2.py:131] throughput: 1.1594963976904666\n",
      "(INFO) 2023-04-14 12:49:16,327 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 2048, 'core_mac_num': 16, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:16,328 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 52, 'data_parallel_size': 3, 'model_parallel_size': 1, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 19}\n",
      "(INFO) 2023-04-14 12:49:16,330 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,386 [api1.py:131] throughput: 0.5229477275958316\n",
      "(INFO) 2023-04-14 12:49:16,387 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 2048, 'core_mac_num': 16, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:16,388 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 52, 'data_parallel_size': 3, 'model_parallel_size': 1, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 19}\n",
      "(INFO) 2023-04-14 12:49:16,390 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,391 [api2.py:131] throughput: 0.5403615432230947\n",
      "(INFO) 2023-04-14 12:49:16,393 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 49, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:16,394 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 220, 'data_parallel_size': 1, 'model_parallel_size': 1, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 207}\n",
      "(INFO) 2023-04-14 12:49:16,402 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,813 [api1.py:131] throughput: 1.0868919931942873\n",
      "(INFO) 2023-04-14 12:49:16,814 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 49, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:16,815 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 220, 'data_parallel_size': 1, 'model_parallel_size': 1, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 207}\n",
      "(INFO) 2023-04-14 12:49:16,822 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,823 [api2.py:131] throughput: 14.275983414813583\n",
      "(INFO) 2023-04-14 12:49:16,824 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 32, 'core_noc_bw': 2048, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:16,825 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 28, 'data_parallel_size': 3, 'model_parallel_size': 4, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 14}\n",
      "(INFO) 2023-04-14 12:49:16,935 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,970 [api1.py:131] throughput: 0.7869689030182335\n",
      "(INFO) 2023-04-14 12:49:16,971 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 32, 'core_noc_bw': 2048, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:16,972 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 28, 'data_parallel_size': 3, 'model_parallel_size': 4, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 14}\n",
      "(INFO) 2023-04-14 12:49:16,973 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:16,975 [api2.py:131] throughput: 99.13082096180688\n",
      "(INFO) 2023-04-14 12:49:16,975 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 2048, 'core_mac_num': 32, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 37, 'reticle_array_w': 20}\n",
      "(INFO) 2023-04-14 12:49:16,977 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 57, 'data_parallel_size': 2, 'model_parallel_size': 3, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 175}\n",
      "(INFO) 2023-04-14 12:49:16,988 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:17,454 [api1.py:131] throughput: 2.4731363129349577\n",
      "(INFO) 2023-04-14 12:49:17,455 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 2048, 'core_mac_num': 32, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 37, 'reticle_array_w': 20}\n",
      "(INFO) 2023-04-14 12:49:17,456 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 57, 'data_parallel_size': 2, 'model_parallel_size': 3, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 175}\n",
      "(INFO) 2023-04-14 12:49:17,464 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:17,465 [api2.py:131] throughput: 121.3353831473239\n",
      "(INFO) 2023-04-14 12:49:17,467 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 4, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 43, 'reticle_array_w': 21}\n",
      "(INFO) 2023-04-14 12:49:17,467 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 23, 'data_parallel_size': 6, 'model_parallel_size': 12, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 7}\n",
      "(INFO) 2023-04-14 12:49:17,480 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:18,386 [api1.py:131] throughput: 0.8968112778463274\n",
      "(INFO) 2023-04-14 12:49:18,387 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 4, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 43, 'reticle_array_w': 21}\n",
      "(INFO) 2023-04-14 12:49:18,388 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 23, 'data_parallel_size': 6, 'model_parallel_size': 12, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 7}\n",
      "(INFO) 2023-04-14 12:49:18,396 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:18,398 [api2.py:131] throughput: 2.8960746759172284\n",
      "(INFO) 2023-04-14 12:49:18,399 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 1024, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 56, 'wafer_mem_bw': 900, 'reticle_array_h': 37, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:18,400 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 19, 'data_parallel_size': 7, 'model_parallel_size': 24, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:18,407 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:18,705 [api1.py:131] throughput: 1.0489530232269488\n",
      "(INFO) 2023-04-14 12:49:18,707 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 1024, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 56, 'wafer_mem_bw': 900, 'reticle_array_h': 37, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:18,708 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 19, 'data_parallel_size': 7, 'model_parallel_size': 24, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:18,712 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:18,713 [api2.py:131] throughput: 5.089686184831378\n",
      "(INFO) 2023-04-14 12:49:18,715 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 8, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:18,715 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 81, 'data_parallel_size': 6, 'model_parallel_size': 8, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:18,717 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:18,755 [api1.py:131] throughput: 0.3970315809972884\n",
      "(INFO) 2023-04-14 12:49:18,756 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 8, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:18,756 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 81, 'data_parallel_size': 6, 'model_parallel_size': 8, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:18,758 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:18,759 [api2.py:131] throughput: 1.4111420343131944\n",
      "(INFO) 2023-04-14 12:49:18,760 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 1024, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 21}\n",
      "(INFO) 2023-04-14 12:49:18,761 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 35, 'data_parallel_size': 4, 'model_parallel_size': 12, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 7}\n",
      "(INFO) 2023-04-14 12:49:18,763 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:18,856 [api1.py:131] throughput: 0.9504031951412764\n",
      "(INFO) 2023-04-14 12:49:18,857 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 1024, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 21}\n",
      "(INFO) 2023-04-14 12:49:18,858 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 35, 'data_parallel_size': 4, 'model_parallel_size': 12, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 7}\n",
      "(INFO) 2023-04-14 12:49:18,861 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:18,862 [api2.py:131] throughput: 4.32412613710186\n",
      "(INFO) 2023-04-14 12:49:18,864 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 64, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 17, 'reticle_array_w': 35}\n",
      "(INFO) 2023-04-14 12:49:18,865 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 468, 'data_parallel_size': 1, 'model_parallel_size': 6, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 19}\n",
      "(INFO) 2023-04-14 12:49:18,874 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:19,346 [api1.py:131] throughput: 0.18603254869286526\n",
      "(INFO) 2023-04-14 12:49:19,347 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 64, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 17, 'reticle_array_w': 35}\n",
      "(INFO) 2023-04-14 12:49:19,348 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 468, 'data_parallel_size': 1, 'model_parallel_size': 6, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 19}\n",
      "(INFO) 2023-04-14 12:49:19,354 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:19,356 [api2.py:131] throughput: 0.5088178508503183\n",
      "(INFO) 2023-04-14 12:49:19,357 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 1024, 'core_mac_num': 64, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 31}\n",
      "(INFO) 2023-04-14 12:49:19,358 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 235, 'data_parallel_size': 2, 'model_parallel_size': 12, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 10}\n",
      "(INFO) 2023-04-14 12:49:19,366 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:19,900 [api1.py:131] throughput: 0.2728530969922783\n",
      "(INFO) 2023-04-14 12:49:19,901 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 1024, 'core_mac_num': 64, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 31}\n",
      "(INFO) 2023-04-14 12:49:19,902 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 235, 'data_parallel_size': 2, 'model_parallel_size': 12, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 10}\n",
      "(INFO) 2023-04-14 12:49:19,910 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:19,912 [api2.py:131] throughput: 0.813860112319313\n",
      "(INFO) 2023-04-14 12:49:19,913 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 1024, 'core_mac_num': 8, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 29}\n",
      "(INFO) 2023-04-14 12:49:19,914 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 378, 'data_parallel_size': 1, 'model_parallel_size': 8, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:19,918 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:20,095 [api1.py:131] throughput: 0.06086618202160143\n",
      "(INFO) 2023-04-14 12:49:20,097 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 1024, 'core_mac_num': 8, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 29}\n",
      "(INFO) 2023-04-14 12:49:20,098 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 378, 'data_parallel_size': 1, 'model_parallel_size': 8, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:20,101 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:20,102 [api2.py:131] throughput: 0.43236288249885885\n",
      "(INFO) 2023-04-14 12:49:20,104 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 58}\n",
      "(INFO) 2023-04-14 12:49:20,105 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 73, 'data_parallel_size': 5, 'model_parallel_size': 6, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 16}\n",
      "(INFO) 2023-04-14 12:49:20,115 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:20,457 [api1.py:131] throughput: 2.3448897781487172\n",
      "(INFO) 2023-04-14 12:49:20,458 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 58}\n",
      "(INFO) 2023-04-14 12:49:20,459 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 73, 'data_parallel_size': 5, 'model_parallel_size': 6, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 16}\n",
      "(INFO) 2023-04-14 12:49:20,464 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:20,465 [api2.py:131] throughput: 1.3588408700920023\n",
      "(INFO) 2023-04-14 12:49:20,466 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 16, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 23, 'reticle_array_w': 38}\n",
      "(INFO) 2023-04-14 12:49:20,467 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 124, 'data_parallel_size': 3, 'model_parallel_size': 8, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 16}\n",
      "(INFO) 2023-04-14 12:49:20,479 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,315 [api1.py:131] throughput: 0.41824695272992773\n",
      "(INFO) 2023-04-14 12:49:21,318 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 16, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 23, 'reticle_array_w': 38}\n",
      "(INFO) 2023-04-14 12:49:21,319 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 124, 'data_parallel_size': 3, 'model_parallel_size': 8, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 16}\n",
      "(INFO) 2023-04-14 12:49:21,326 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,327 [api2.py:131] throughput: 1.2812897481998888\n",
      "(INFO) 2023-04-14 12:49:21,328 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 1024, 'core_mac_num': 64, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 13, 'reticle_array_w': 14}\n",
      "(INFO) 2023-04-14 12:49:21,329 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 319, 'data_parallel_size': 1, 'model_parallel_size': 6, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:21,333 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,430 [api1.py:131] throughput: 0.049380883046439325\n",
      "(INFO) 2023-04-14 12:49:21,430 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 1024, 'core_mac_num': 64, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 13, 'reticle_array_w': 14}\n",
      "(INFO) 2023-04-14 12:49:21,431 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 319, 'data_parallel_size': 1, 'model_parallel_size': 6, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:21,433 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,434 [api2.py:131] throughput: 0.6588280562151654\n",
      "(INFO) 2023-04-14 12:49:21,435 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 4, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:21,436 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 34, 'data_parallel_size': 6, 'model_parallel_size': 12, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:21,438 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,483 [api1.py:131] throughput: 0.11495991626800604\n",
      "(INFO) 2023-04-14 12:49:21,484 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 4, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:21,484 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 34, 'data_parallel_size': 6, 'model_parallel_size': 12, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:21,486 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,487 [api2.py:131] throughput: 4.261920433373643\n",
      "(INFO) 2023-04-14 12:49:21,488 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 1024, 'core_mac_num': 16, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 31, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:21,488 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 66, 'data_parallel_size': 4, 'model_parallel_size': 6, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:21,492 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,759 [api1.py:131] throughput: 0.07701540497499759\n",
      "(INFO) 2023-04-14 12:49:21,760 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 1024, 'core_mac_num': 16, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 31, 'reticle_array_w': 12}\n",
      "(INFO) 2023-04-14 12:49:21,761 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 66, 'data_parallel_size': 4, 'model_parallel_size': 6, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:21,766 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,768 [api2.py:131] throughput: 1.2269374514519056\n",
      "(INFO) 2023-04-14 12:49:21,769 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 72, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:21,770 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 41, 'data_parallel_size': 7, 'model_parallel_size': 6, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 8}\n",
      "(INFO) 2023-04-14 12:49:21,774 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,835 [api1.py:131] throughput: 1.4698686895188955\n",
      "(INFO) 2023-04-14 12:49:21,836 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 72, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:21,837 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 41, 'data_parallel_size': 7, 'model_parallel_size': 6, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 8}\n",
      "(INFO) 2023-04-14 12:49:21,839 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,840 [api2.py:131] throughput: 1.6487366315019123\n",
      "(INFO) 2023-04-14 12:49:21,841 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:21,842 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 103, 'data_parallel_size': 2, 'model_parallel_size': 1, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 8}\n",
      "(INFO) 2023-04-14 12:49:21,846 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,916 [api1.py:131] throughput: 0.25162839844886287\n",
      "(INFO) 2023-04-14 12:49:21,917 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 11}\n",
      "(INFO) 2023-04-14 12:49:21,918 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 103, 'data_parallel_size': 2, 'model_parallel_size': 1, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 8}\n",
      "(INFO) 2023-04-14 12:49:21,919 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:21,920 [api2.py:131] throughput: 0.4129063897359305\n",
      "(INFO) 2023-04-14 12:49:21,921 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 19}\n",
      "(INFO) 2023-04-14 12:49:21,922 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 16, 'data_parallel_size': 13, 'model_parallel_size': 6, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 9}\n",
      "(INFO) 2023-04-14 12:49:21,924 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,015 [api1.py:131] throughput: 0.741598255689959\n",
      "(INFO) 2023-04-14 12:49:22,016 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 19}\n",
      "(INFO) 2023-04-14 12:49:22,017 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 16, 'data_parallel_size': 13, 'model_parallel_size': 6, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 9}\n",
      "(INFO) 2023-04-14 12:49:22,147 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,149 [api2.py:131] throughput: 2.7598339550026196\n",
      "(INFO) 2023-04-14 12:49:22,149 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 8, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 64, 'wafer_mem_bw': 900, 'reticle_array_h': 27, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:22,150 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 110, 'data_parallel_size': 2, 'model_parallel_size': 24, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:22,153 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,285 [api1.py:131] throughput: 0.2215394809963504\n",
      "(INFO) 2023-04-14 12:49:22,287 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 8, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 64, 'wafer_mem_bw': 900, 'reticle_array_h': 27, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:22,288 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 110, 'data_parallel_size': 2, 'model_parallel_size': 24, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:22,291 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,292 [api2.py:131] throughput: 1.893574603486488\n",
      "(INFO) 2023-04-14 12:49:22,294 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 80, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:22,295 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 48, 'data_parallel_size': 6, 'model_parallel_size': 1, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 12}\n",
      "(INFO) 2023-04-14 12:49:22,296 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,358 [api1.py:131] throughput: 0.510247933797935\n",
      "(INFO) 2023-04-14 12:49:22,359 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 40, 'core_array_w': 80, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:22,360 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 48, 'data_parallel_size': 6, 'model_parallel_size': 1, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 12}\n",
      "(INFO) 2023-04-14 12:49:22,363 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,364 [api2.py:131] throughput: 0.42512855604569255\n",
      "(INFO) 2023-04-14 12:49:22,365 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 8, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 72, 'core_array_w': 64, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:22,366 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 138, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:22,368 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,409 [api1.py:131] throughput: 0.14820010240555936\n",
      "(INFO) 2023-04-14 12:49:22,410 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 8, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 72, 'core_array_w': 64, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:22,411 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 138, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:22,413 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,414 [api2.py:131] throughput: 0.5660145792314634\n",
      "(INFO) 2023-04-14 12:49:22,415 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 1024, 'core_mac_num': 32, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:22,416 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 244, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:22,419 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,579 [api1.py:131] throughput: 0.019676154981224\n",
      "(INFO) 2023-04-14 12:49:22,580 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 1024, 'core_mac_num': 32, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:22,581 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 244, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:22,584 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,585 [api2.py:131] throughput: 0.6992252017141349\n",
      "(INFO) 2023-04-14 12:49:22,586 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 8, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 33}\n",
      "(INFO) 2023-04-14 12:49:22,587 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 13, 'data_parallel_size': 3, 'model_parallel_size': 3, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:22,593 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,748 [api1.py:131] throughput: 0.5618576891931997\n",
      "(INFO) 2023-04-14 12:49:22,749 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 8, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 33}\n",
      "(INFO) 2023-04-14 12:49:22,750 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 13, 'data_parallel_size': 3, 'model_parallel_size': 3, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:22,754 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:22,757 [api2.py:131] throughput: 1.0600063962404866\n",
      "(INFO) 2023-04-14 12:49:22,758 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 8, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 28, 'reticle_array_w': 18}\n",
      "(INFO) 2023-04-14 12:49:22,759 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 149, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:22,770 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,223 [api1.py:131] throughput: 0.23627545801903027\n",
      "(INFO) 2023-04-14 12:49:23,224 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 8, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 28, 'reticle_array_w': 18}\n",
      "(INFO) 2023-04-14 12:49:23,225 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 149, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:23,230 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,231 [api2.py:131] throughput: 1.1538361562996424\n",
      "(INFO) 2023-04-14 12:49:23,232 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 256, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:23,233 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 453, 'data_parallel_size': 1, 'model_parallel_size': 4, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 22}\n",
      "(INFO) 2023-04-14 12:49:23,234 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,283 [api1.py:131] throughput: 0.22609969841832323\n",
      "(INFO) 2023-04-14 12:49:23,284 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 256, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:23,285 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 453, 'data_parallel_size': 1, 'model_parallel_size': 4, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 22}\n",
      "(INFO) 2023-04-14 12:49:23,287 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,288 [api2.py:131] throughput: 115.77395266251462\n",
      "(INFO) 2023-04-14 12:49:23,288 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 32, 'core_noc_bw': 2048, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 24}\n",
      "(INFO) 2023-04-14 12:49:23,289 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 120, 'data_parallel_size': 4, 'model_parallel_size': 1, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:23,292 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,400 [api1.py:131] throughput: 0.1250167142346263\n",
      "(INFO) 2023-04-14 12:49:23,401 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 32, 'core_noc_bw': 2048, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 8, 'reticle_array_w': 24}\n",
      "(INFO) 2023-04-14 12:49:23,402 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 120, 'data_parallel_size': 4, 'model_parallel_size': 1, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:23,404 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,405 [api2.py:131] throughput: 0.32304357368850306\n",
      "(INFO) 2023-04-14 12:49:23,406 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 64, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 30}\n",
      "(INFO) 2023-04-14 12:49:23,407 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 13, 'data_parallel_size': 6, 'model_parallel_size': 8, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:23,412 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,520 [api1.py:131] throughput: 0.47475288178189573\n",
      "(INFO) 2023-04-14 12:49:23,521 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 64, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 30}\n",
      "(INFO) 2023-04-14 12:49:23,522 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 13, 'data_parallel_size': 6, 'model_parallel_size': 8, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 1}\n",
      "(INFO) 2023-04-14 12:49:23,524 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,526 [api2.py:131] throughput: 2.350106379727376\n",
      "(INFO) 2023-04-14 12:49:23,527 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 80, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 16}\n",
      "(INFO) 2023-04-14 12:49:23,528 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 217, 'data_parallel_size': 2, 'model_parallel_size': 4, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 8}\n",
      "(INFO) 2023-04-14 12:49:23,532 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,576 [api1.py:131] throughput: 0.7049533246456015\n",
      "(INFO) 2023-04-14 12:49:23,577 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 256, 'core_mac_num': 4, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 80, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 6, 'reticle_array_w': 16}\n",
      "(INFO) 2023-04-14 12:49:23,578 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 217, 'data_parallel_size': 2, 'model_parallel_size': 4, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 8}\n",
      "(INFO) 2023-04-14 12:49:23,580 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,581 [api2.py:131] throughput: 0.8458027557097146\n",
      "(INFO) 2023-04-14 12:49:23,582 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:23,582 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 29, 'data_parallel_size': 9, 'model_parallel_size': 4, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 7}\n",
      "(INFO) 2023-04-14 12:49:23,584 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,628 [api1.py:131] throughput: 1.206316295283377\n",
      "(INFO) 2023-04-14 12:49:23,629 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 2048, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:23,630 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 29, 'data_parallel_size': 9, 'model_parallel_size': 4, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 7}\n",
      "(INFO) 2023-04-14 12:49:23,632 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,634 [api2.py:131] throughput: 1.3747916651708934\n",
      "(INFO) 2023-04-14 12:49:23,635 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 14}\n",
      "(INFO) 2023-04-14 12:49:23,635 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 46, 'data_parallel_size': 6, 'model_parallel_size': 3, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:23,638 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,696 [api1.py:131] throughput: 0.2636423403861114\n",
      "(INFO) 2023-04-14 12:49:23,698 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 7, 'reticle_array_w': 14}\n",
      "(INFO) 2023-04-14 12:49:23,698 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 46, 'data_parallel_size': 6, 'model_parallel_size': 3, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 2}\n",
      "(INFO) 2023-04-14 12:49:23,701 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:23,702 [api2.py:131] throughput: 0.8926640317801151\n",
      "(INFO) 2023-04-14 12:49:23,703 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 32, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 41}\n",
      "(INFO) 2023-04-14 12:49:23,704 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 100, 'data_parallel_size': 2, 'model_parallel_size': 4, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 45}\n",
      "(INFO) 2023-04-14 12:49:23,712 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:24,069 [api1.py:131] throughput: 3.226207092213668\n",
      "(INFO) 2023-04-14 12:49:24,071 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 32, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 41}\n",
      "(INFO) 2023-04-14 12:49:24,072 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 100, 'data_parallel_size': 2, 'model_parallel_size': 4, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 45}\n",
      "(INFO) 2023-04-14 12:49:24,076 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:24,078 [api2.py:131] throughput: 0.9541758359892525\n",
      "(INFO) 2023-04-14 12:49:24,079 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 1024, 'core_mac_num': 32, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 37, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:24,080 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 37, 'data_parallel_size': 2, 'model_parallel_size': 1, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 62}\n",
      "(INFO) 2023-04-14 12:49:24,086 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:24,270 [api1.py:131] throughput: 1.576687694704218\n",
      "(INFO) 2023-04-14 12:49:24,271 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 1024, 'core_mac_num': 32, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 48, 'wafer_mem_bw': 900, 'reticle_array_h': 37, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:24,272 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 37, 'data_parallel_size': 2, 'model_parallel_size': 1, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 62}\n",
      "(INFO) 2023-04-14 12:49:24,276 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:24,277 [api2.py:131] throughput: 0.48375142000716076\n",
      "(INFO) 2023-04-14 12:49:24,278 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 32, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 55, 'reticle_array_w': 38}\n",
      "(INFO) 2023-04-14 12:49:24,278 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 170, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 295}\n",
      "(INFO) 2023-04-14 12:49:24,304 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:26,772 [api1.py:131] throughput: 2.576275533593986\n",
      "(INFO) 2023-04-14 12:49:26,774 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 32, 'core_noc_bw': 32, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 55, 'reticle_array_w': 38}\n",
      "(INFO) 2023-04-14 12:49:26,775 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 170, 'data_parallel_size': 2, 'model_parallel_size': 2, 'tensor_parallel_size': 6, 'num_reticle_per_pipeline_stage': 295}\n",
      "(INFO) 2023-04-14 12:49:26,796 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:26,798 [api2.py:131] throughput: 0.5309618122513712\n",
      "(INFO) 2023-04-14 12:49:26,798 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 1024, 'core_mac_num': 8, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 18}\n",
      "(INFO) 2023-04-14 12:49:26,799 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 93, 'data_parallel_size': 2, 'model_parallel_size': 8, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 89}\n",
      "(INFO) 2023-04-14 12:49:26,805 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:26,916 [api1.py:131] throughput: 7.409210611126474\n",
      "(INFO) 2023-04-14 12:49:26,917 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 1024, 'core_mac_num': 8, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 19, 'reticle_array_w': 18}\n",
      "(INFO) 2023-04-14 12:49:26,918 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 93, 'data_parallel_size': 2, 'model_parallel_size': 8, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 89}\n",
      "(INFO) 2023-04-14 12:49:26,922 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:26,923 [api2.py:131] throughput: 2.4565598886908426\n",
      "(INFO) 2023-04-14 12:49:26,923 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 64, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 16, 'reticle_array_w': 31}\n",
      "(INFO) 2023-04-14 12:49:26,924 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 234, 'data_parallel_size': 2, 'model_parallel_size': 4, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 7}\n",
      "(INFO) 2023-04-14 12:49:26,933 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:27,341 [api1.py:131] throughput: 0.2624156935509904\n",
      "(INFO) 2023-04-14 12:49:27,342 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 1024, 'core_mac_num': 64, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 16, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 16, 'reticle_array_w': 31}\n",
      "(INFO) 2023-04-14 12:49:27,343 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 234, 'data_parallel_size': 2, 'model_parallel_size': 4, 'tensor_parallel_size': 12, 'num_reticle_per_pipeline_stage': 7}\n",
      "(INFO) 2023-04-14 12:49:27,348 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:27,349 [api2.py:131] throughput: 0.5805707657776181\n",
      "(INFO) 2023-04-14 12:49:27,351 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 8, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 41, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:27,352 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 49, 'data_parallel_size': 6, 'model_parallel_size': 4, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 27}\n",
      "(INFO) 2023-04-14 12:49:27,358 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:27,632 [api1.py:131] throughput: 1.6850732283589125\n",
      "(INFO) 2023-04-14 12:49:27,633 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 512, 'core_mac_num': 8, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 32, 'wafer_mem_bw': 900, 'reticle_array_h': 41, 'reticle_array_w': 10}\n",
      "(INFO) 2023-04-14 12:49:27,634 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 49, 'data_parallel_size': 6, 'model_parallel_size': 4, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 27}\n",
      "(INFO) 2023-04-14 12:49:27,638 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:27,639 [api2.py:131] throughput: 1.5721733643963254\n",
      "(INFO) 2023-04-14 12:49:27,641 [api1.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 8, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 30, 'reticle_array_w': 47}\n",
      "(INFO) 2023-04-14 12:49:27,641 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 56, 'data_parallel_size': 7, 'model_parallel_size': 1, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 186}\n",
      "(INFO) 2023-04-14 12:49:27,658 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:28,572 [api1.py:131] throughput: 1.2850783106471437\n",
      "(INFO) 2023-04-14 12:49:28,573 [api2.py:116] Design point: {'core_buffer_size': 64, 'core_buffer_bw': 256, 'core_mac_num': 8, 'core_noc_bw': 512, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 8, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 30, 'reticle_array_w': 47}\n",
      "(INFO) 2023-04-14 12:49:28,574 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 56, 'data_parallel_size': 7, 'model_parallel_size': 1, 'tensor_parallel_size': 4, 'num_reticle_per_pipeline_stage': 186}\n",
      "(INFO) 2023-04-14 12:49:28,587 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:28,589 [api2.py:131] throughput: 0.44036461078510103\n",
      "(INFO) 2023-04-14 12:49:28,590 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 1024, 'core_mac_num': 8, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 42}\n",
      "(INFO) 2023-04-14 12:49:28,591 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 53, 'data_parallel_size': 6, 'model_parallel_size': 24, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 14}\n",
      "(INFO) 2023-04-14 12:49:28,599 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:28,848 [api1.py:131] throughput: 0.9504745533695088\n",
      "(INFO) 2023-04-14 12:49:28,849 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 1024, 'core_mac_num': 8, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 12, 'reticle_array_w': 42}\n",
      "(INFO) 2023-04-14 12:49:28,850 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 53, 'data_parallel_size': 6, 'model_parallel_size': 24, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 14}\n",
      "(INFO) 2023-04-14 12:49:28,855 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:28,856 [api2.py:131] throughput: 10.488660834635606\n",
      "(INFO) 2023-04-14 12:49:28,858 [api1.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 25}\n",
      "(INFO) 2023-04-14 12:49:28,859 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 63, 'data_parallel_size': 6, 'model_parallel_size': 3, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:28,863 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:28,949 [api1.py:131] throughput: 0.7151080228037271\n",
      "(INFO) 2023-04-14 12:49:28,950 [api2.py:116] Design point: {'core_buffer_size': 48, 'core_buffer_bw': 512, 'core_mac_num': 4, 'core_noc_bw': 256, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 16, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 25}\n",
      "(INFO) 2023-04-14 12:49:28,951 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 63, 'data_parallel_size': 6, 'model_parallel_size': 3, 'tensor_parallel_size': 24, 'num_reticle_per_pipeline_stage': 5}\n",
      "(INFO) 2023-04-14 12:49:28,954 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:28,955 [api2.py:131] throughput: 0.8383067969771313\n",
      "(INFO) 2023-04-14 12:49:28,957 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 64, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 15, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:28,958 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 213, 'data_parallel_size': 1, 'model_parallel_size': 8, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:28,961 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:29,033 [api1.py:131] throughput: 0.16537760547469327\n",
      "(INFO) 2023-04-14 12:49:29,035 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 64, 'core_noc_bw': 64, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 24, 'wafer_mem_bw': 900, 'reticle_array_h': 15, 'reticle_array_w': 9}\n",
      "(INFO) 2023-04-14 12:49:29,035 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 213, 'data_parallel_size': 1, 'model_parallel_size': 8, 'tensor_parallel_size': 3, 'num_reticle_per_pipeline_stage': 4}\n",
      "(INFO) 2023-04-14 12:49:29,038 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:29,039 [api2.py:131] throughput: 1.0464357067088979\n",
      "(INFO) 2023-04-14 12:49:29,040 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 64, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 25}\n",
      "(INFO) 2023-04-14 12:49:29,041 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 229, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 79}\n",
      "(INFO) 2023-04-14 12:49:29,045 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:29,171 [api1.py:131] throughput: 0.8701574315376757\n",
      "(INFO) 2023-04-14 12:49:29,172 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 512, 'core_mac_num': 64, 'core_noc_bw': 128, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 48, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 25}\n",
      "(INFO) 2023-04-14 12:49:29,173 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 229, 'data_parallel_size': 1, 'model_parallel_size': 3, 'tensor_parallel_size': 1, 'num_reticle_per_pipeline_stage': 79}\n",
      "(INFO) 2023-04-14 12:49:29,176 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:29,177 [api2.py:131] throughput: 174.28714166515667\n",
      "(INFO) 2023-04-14 12:49:29,177 [api1.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 8, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:29,178 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 389, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 3}\n",
      "(INFO) 2023-04-14 12:49:29,180 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:29,325 [api1.py:131] throughput: 0.0746602136032295\n",
      "(INFO) 2023-04-14 12:49:29,326 [api2.py:116] Design point: {'core_buffer_size': 32, 'core_buffer_bw': 128, 'core_mac_num': 8, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 32, 'core_array_w': 40, 'wafer_mem_bw': 900, 'reticle_array_h': 9, 'reticle_array_w': 8}\n",
      "(INFO) 2023-04-14 12:49:29,327 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 389, 'data_parallel_size': 1, 'model_parallel_size': 12, 'tensor_parallel_size': 2, 'num_reticle_per_pipeline_stage': 3}\n",
      "(INFO) 2023-04-14 12:49:29,328 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:29,329 [api2.py:131] throughput: 0.7610825899841707\n",
      "(INFO) 2023-04-14 12:49:29,330 [api1.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 2048, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 33}\n",
      "(INFO) 2023-04-14 12:49:29,331 [api1.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 61, 'data_parallel_size': 1, 'model_parallel_size': 4, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 18}\n",
      "(INFO) 2023-04-14 12:49:29,334 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:29,479 [api1.py:131] throughput: 2.1154955116120995\n",
      "(INFO) 2023-04-14 12:49:29,480 [api2.py:116] Design point: {'core_buffer_size': 128, 'core_buffer_bw': 2048, 'core_mac_num': 4, 'core_noc_bw': 1024, 'core_noc_vc': 4, 'core_noc_buffer_size': 4, 'reticle_bw': 1, 'core_array_h': 24, 'core_array_w': 8, 'wafer_mem_bw': 900, 'reticle_array_h': 10, 'reticle_array_w': 33}\n",
      "(INFO) 2023-04-14 12:49:29,481 [api2.py:117] Model parameters: {'attention_heads': 24, 'hidden_size': 2304, 'sequence_length': 2048, 'number_of_layers': 24, 'mini_batch_size': 512, 'micro_batch_size': 61, 'data_parallel_size': 1, 'model_parallel_size': 4, 'tensor_parallel_size': 8, 'num_reticle_per_pipeline_stage': 18}\n",
      "(INFO) 2023-04-14 12:49:29,486 [wse_attn.py:412] Calculating training throughput of attention module\n",
      "(INFO) 2023-04-14 12:49:29,487 [api2.py:131] throughput: 1.1153454632459074\n",
      "100%|██████████| 100/100 [00:00<00:00, 29820.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.515959595959596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utility import dse, parse_pickle\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "kt = dse.KT_evaluator()\n",
    "print(kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.515959595959596\n"
     ]
    }
   ],
   "source": [
    "print(kt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
